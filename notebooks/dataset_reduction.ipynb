{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59421ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyse de C:\\Users\\jansc\\OneDrive\\Bureau\\ECAM_local\\ai_project_ma2\\ia-llm-project\\data\\dataset\\garbage_dataset...\n",
      "‚úÖ Trouv√© 3846 images sur 7 classes.\n",
      "üìä Objectif : ~14 images/classe.\n",
      "üì¶ Total s√©lectionn√© : 98 images.\n",
      "\n",
      "üöÄ Cr√©ation de la structure dans 'C:\\Users\\jansc\\OneDrive\\Bureau\\ECAM_local\\ai_project_ma2\\ia-llm-project\\data\\dataset\\garbage_dataset_100_reduction'...\n",
      "‚úÖ Termin√© ! L'arborescence respecte le format demand√©.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "\n",
    "BASE_DIR = Path('..').resolve()\n",
    "# Dossier source (votre dataset g√©ant actuel)\n",
    "SOURCE_DIR = BASE_DIR / \"data\" / \"dataset\" / \"garbage_dataset\"\n",
    "\n",
    "# Dossier de destination (sera cr√©√© s'il n'existe pas)\n",
    "DEST_DIR = BASE_DIR / \"data\" / \"dataset\" / \"garbage_dataset_100_reduction\" \n",
    "\n",
    "# Nombre total d'images voulu (ex: 1000)\n",
    "TARGET_TOTAL = 100\n",
    "\n",
    "# R√©partition (Train / Valid / Test)\n",
    "# Notez l'usage de 'valid' pour respecter votre tree\n",
    "SPLIT_RATIOS = {'train': 0.8, 'valid': 0.1, 'test': 0.1}\n",
    "\n",
    "# Extensions d'images accept√©es\n",
    "IMG_EXT = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "# =================================================\n",
    "\n",
    "def get_class_from_label(label_path):\n",
    "    \"\"\"Lit le premier ID de classe dans le fichier .txt YOLO.\"\"\"\n",
    "    if not os.path.exists(label_path):\n",
    "        return None\n",
    "    try:\n",
    "        with open(label_path, 'r') as f:\n",
    "            line = f.readline()\n",
    "            if not line.strip(): return None\n",
    "            # Format YOLO : class_id x y w h\n",
    "            return int(line.split()[0]) \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    print(f\"üîç Analyse de {SOURCE_DIR}...\")\n",
    "    \n",
    "    files_by_class = defaultdict(list)\n",
    "    image_count = 0\n",
    "    \n",
    "    # 1. SCAN ET INDEXATION (M√™me logique que pr√©c√©demment)\n",
    "    for root, _, files in os.walk(SOURCE_DIR):\n",
    "        for file in files:\n",
    "            ext = os.path.splitext(file)[1].lower()\n",
    "            if ext in IMG_EXT:\n",
    "                img_path = os.path.join(root, file)\n",
    "                base_name = os.path.splitext(file)[0]\n",
    "                \n",
    "                # Recherche du label (m√©thode robuste)\n",
    "                label_path = os.path.join(root, base_name + \".txt\")\n",
    "                if not os.path.exists(label_path):\n",
    "                    # Essai structure parall√®le images/labels\n",
    "                    label_path = img_path.replace(f\"{os.sep}images{os.sep}\", f\"{os.sep}labels{os.sep}\")\n",
    "                    label_path = os.path.splitext(label_path)[0] + \".txt\"\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    class_id = get_class_from_label(label_path)\n",
    "                    if class_id is not None:\n",
    "                        files_by_class[class_id].append((img_path, label_path))\n",
    "                        image_count += 1\n",
    "\n",
    "    classes = list(files_by_class.keys())\n",
    "    if not classes:\n",
    "        print(\"‚ùå Erreur : Aucune donn√©e trouv√©e.\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚úÖ Trouv√© {image_count} images sur {len(classes)} classes.\")\n",
    "\n",
    "    # 2. S√âLECTION √âQUILIBR√âE AM√âLIOR√âE\n",
    "    quota = TARGET_TOTAL // len(classes)\n",
    "    final_selection = []\n",
    "    \n",
    "    print(f\"üìä Objectif : {quota} images/classe (total vis√©: {quota * len(classes)}).\")\n",
    "    \n",
    "    # Statistiques par classe\n",
    "    class_stats = {}\n",
    "    \n",
    "    for class_id in sorted(classes):\n",
    "        pairs = files_by_class[class_id]\n",
    "        available = len(pairs)\n",
    "        \n",
    "        if available < quota:\n",
    "            print(f\"‚ö†Ô∏è  Classe {class_id}: seulement {available} images disponibles (quota: {quota})\")\n",
    "        \n",
    "        random.shuffle(pairs)\n",
    "        selected = pairs[:min(quota, available)]\n",
    "        final_selection.extend(selected)\n",
    "        class_stats[class_id] = len(selected)\n",
    "\n",
    "    # Affichage du bilan par classe\n",
    "    print(f\"\\nüìä R√©partition par classe:\")\n",
    "    for class_id in sorted(class_stats.keys()):\n",
    "        print(f\"   Classe {class_id}: {class_stats[class_id]} images\")\n",
    "    \n",
    "    print(f\"\\nüì¶ Total s√©lectionn√© : {len(final_selection)} images.\")\n",
    "    \n",
    "    # V√©rification de l'√©quilibre\n",
    "    min_imgs = min(class_stats.values())\n",
    "    max_imgs = max(class_stats.values())\n",
    "    if max_imgs - min_imgs > quota * 0.1:  # Plus de 10% de diff√©rence\n",
    "        print(f\"‚ö†Ô∏è  D√©s√©quilibre d√©tect√©: min={min_imgs}, max={max_imgs}\")\n",
    "\n",
    "    random.shuffle(final_selection)\n",
    "\n",
    "    # 3. DISTRIBUTION ET COPIE (Nouvelle structure)\n",
    "    n_train = int(len(final_selection) * SPLIT_RATIOS['train'])\n",
    "    n_valid = int(len(final_selection) * SPLIT_RATIOS['valid'])\n",
    "    \n",
    "    # D√©coupage de la liste\n",
    "    datasets = {\n",
    "        'train': final_selection[:n_train],\n",
    "        'valid': final_selection[n_train:n_train+n_valid],\n",
    "        'test': final_selection[n_train+n_valid:]\n",
    "    }\n",
    "\n",
    "    print(f\"\\nüöÄ Cr√©ation de la structure dans '{DEST_DIR}'...\")\n",
    "\n",
    "    for split_name, pairs in datasets.items():\n",
    "        # Construction des chemins selon votre Tree\n",
    "        # ex: garbage_dataset/train/images\n",
    "        split_img_dir = os.path.join(DEST_DIR, split_name, 'images')\n",
    "        # ex: garbage_dataset/train/labels\n",
    "        split_lbl_dir = os.path.join(DEST_DIR, split_name, 'labels')\n",
    "        \n",
    "        os.makedirs(split_img_dir, exist_ok=True)\n",
    "        os.makedirs(split_lbl_dir, exist_ok=True)\n",
    "\n",
    "        for img_src, lbl_src in pairs:\n",
    "            shutil.copy2(img_src, os.path.join(split_img_dir, os.path.basename(img_src)))\n",
    "            shutil.copy2(lbl_src, os.path.join(split_lbl_dir, os.path.basename(lbl_src)))\n",
    "    \n",
    "    # Copie du fichier data.yaml\n",
    "    source_yaml = os.path.join(SOURCE_DIR, 'data.yaml')\n",
    "    dest_yaml = os.path.join(DEST_DIR, 'data.yaml')\n",
    "    \n",
    "    if os.path.exists(source_yaml):\n",
    "        shutil.copy2(source_yaml, dest_yaml)\n",
    "        print(f\"‚úÖ Fichier data.yaml copi√©.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Fichier data.yaml introuvable dans {SOURCE_DIR}\")\n",
    "            \n",
    "    print(f\"‚úÖ Termin√© ! L'arborescence respecte le format demand√©.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a99266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path('..').resolve()\n",
    "DEST_DIR = BASE_DIR / \"data\" / \"dataset\" / \"garbage_dataset_100_reduction\"\n",
    "\n",
    "def get_class_from_label(label_path):\n",
    "    \"\"\"Lit le premier ID de classe dans le fichier .txt YOLO.\"\"\"\n",
    "    if not os.path.exists(label_path):\n",
    "        return None\n",
    "    try:\n",
    "        with open(label_path, 'r') as f:\n",
    "            line = f.readline()\n",
    "            if not line.strip(): return None\n",
    "            return int(line.split()[0])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Comptage des classes dans chaque split\n",
    "splits = ['train', 'valid', 'test']\n",
    "class_distribution = {split: defaultdict(int) for split in splits}\n",
    "\n",
    "for split in splits:\n",
    "    labels_dir = DEST_DIR / split / 'labels'\n",
    "    if labels_dir.exists():\n",
    "        for label_file in labels_dir.glob('*.txt'):\n",
    "            class_id = get_class_from_label(str(label_file))\n",
    "            if class_id is not None:\n",
    "                class_distribution[split][class_id] += 1\n",
    "\n",
    "# Pr√©paration des donn√©es pour le graphique\n",
    "all_classes = sorted(set().union(*[d.keys() for d in class_distribution.values()]))\n",
    "train_counts = [class_distribution['train'][c] for c in all_classes]\n",
    "valid_counts = [class_distribution['valid'][c] for c in all_classes]\n",
    "test_counts = [class_distribution['test'][c] for c in all_classes]\n",
    "\n",
    "# Cr√©ation du graphique\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Graphique 1: Distribution par split\n",
    "x = range(len(all_classes))\n",
    "width = 0.25\n",
    "\n",
    "ax1.bar([i - width for i in x], train_counts, width, label='Train', alpha=0.8)\n",
    "ax1.bar(x, valid_counts, width, label='Valid', alpha=0.8)\n",
    "ax1.bar([i + width for i in x], test_counts, width, label='Test', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Classe')\n",
    "ax1.set_ylabel('Nombre d\\'images')\n",
    "ax1.set_title('Distribution des classes par split')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(all_classes)\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Graphique 2: Distribution totale\n",
    "total_counts = [train_counts[i] + valid_counts[i] + test_counts[i] for i in range(len(all_classes))]\n",
    "ax2.bar(all_classes, total_counts, color='steelblue', alpha=0.8)\n",
    "ax2.set_xlabel('Classe')\n",
    "ax2.set_ylabel('Nombre total d\\'images')\n",
    "ax2.set_title('Distribution totale des classes')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Ajout des valeurs sur les barres\n",
    "for i, v in enumerate(total_counts):\n",
    "    ax2.text(all_classes[i], v + 0.5, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä R√©sum√© de la distribution:\")\n",
    "print(f\"{'Classe':<10} {'Train':<10} {'Valid':<10} {'Test':<10} {'Total':<10}\")\n",
    "print(\"-\" * 50)\n",
    "for c in all_classes:\n",
    "    total = train_counts[all_classes.index(c)] + valid_counts[all_classes.index(c)] + test_counts[all_classes.index(c)]\n",
    "    print(f\"{c:<10} {train_counts[all_classes.index(c)]:<10} {valid_counts[all_classes.index(c)]:<10} {test_counts[all_classes.index(c)]:<10} {total:<10}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
